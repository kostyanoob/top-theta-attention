# Reproducing the main results of the ArXiV paper

## Q&A datasets - prefill-only tasks
Below are the commands used for running QA datasets experiments primary experiments for the paper.
First run the experiments. Each run will be uniquely identified by a TIMESTAMP, its statistics will be dumped into a subdirectory `products/<TIMESTAMP>`, the acc_norm score will be written alongside the TIMESTAMP inside the results-Llama directory, in a text file. After you run the experiments - you can visualzie the acc_norm as a function of kept attention elements by using `notebooks/4-accuracy-kept_attn-kept_vrow-tradeoff_QA.ipynb` - just update the TIMESTAMPS of the corresponding runs that you want to plot.
```bash
# llama2-7b QA:
#   baseline (no sparsification)
python test_llama.py --llama 2-7 --task arc_challenge --mode 3 --timestamps
python test_llama.py --llama 2-7 --task arc_easy --mode 3 --timestamps
python test_llama.py --llama 2-7 --task hellaswag --mode 3 --timestamps
#   top-theta
python test_llama.py --llama 2-7 --task arc_challenge --mode 0 --k 16  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 2-7 --task arc_challenge --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 2-7 --task arc_challenge --mode 0 --k 64  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 2-7 --task arc_challenge --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 2-7 --task arc_challenge --mode 0 --k 256 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 2-7 --task arc_challenge --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 2-7 --task arc_challenge --mode 0 --k 16  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_challenge --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_challenge --mode 0 --k 64  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_challenge --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_challenge --mode 0 --k 256 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_challenge --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_easy --mode 0 --k 16  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc
python test_llama.py --llama 2-7 --task arc_easy --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc
python test_llama.py --llama 2-7 --task arc_easy --mode 0 --k 64  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc
python test_llama.py --llama 2-7 --task arc_easy --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc
python test_llama.py --llama 2-7 --task arc_easy --mode 0 --k 256 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc
python test_llama.py --llama 2-7 --task arc_easy --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc
python test_llama.py --llama 2-7 --task arc_easy --mode 0 --k 16  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_easy --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_easy --mode 0 --k 64  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_easy --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_easy --mode 0 --k 256 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_easy --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task hellaswag --mode 0 --k 16  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 2-7 --task hellaswag --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 2-7 --task hellaswag --mode 0 --k 64  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 2-7 --task hellaswag --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 2-7 --task hellaswag --mode 0 --k 256 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 2-7 --task hellaswag --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 2-7 --task hellaswag --mode 0 --k 16  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task hellaswag --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task hellaswag --mode 0 --k 64  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task hellaswag --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task hellaswag --mode 0 --k 256 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 2-7 --task hellaswag --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
#   top-k
python test_llama.py --llama 2-7 --task arc_challenge --mode 1 --k 16  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 2-7 --task arc_challenge --mode 1 --k 32  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 2-7 --task arc_challenge --mode 1 --k 64  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 2-7 --task arc_challenge --mode 1 --k 128 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 2-7 --task arc_challenge --mode 1 --k 256 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 2-7 --task arc_challenge --mode 1 --k 512 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 2-7 --task arc_challenge --mode 1 --k 16  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_challenge --mode 1 --k 32  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_challenge --mode 1 --k 64  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_challenge --mode 1 --k 128 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_challenge --mode 1 --k 256 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_challenge --mode 1 --k 512 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_easy --mode 1 --k 16  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc
python test_llama.py --llama 2-7 --task arc_easy --mode 1 --k 32  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc
python test_llama.py --llama 2-7 --task arc_easy --mode 1 --k 64  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc
python test_llama.py --llama 2-7 --task arc_easy --mode 1 --k 128 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc
python test_llama.py --llama 2-7 --task arc_easy --mode 1 --k 256 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc
python test_llama.py --llama 2-7 --task arc_easy --mode 1 --k 512 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc
python test_llama.py --llama 2-7 --task arc_easy --mode 1 --k 16  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_easy --mode 1 --k 32  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_easy --mode 1 --k 64  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_easy --mode 1 --k 128 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_easy --mode 1 --k 256 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task arc_easy --mode 1 --k 512 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task hellaswag --mode 1 --k 16  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 2-7 --task hellaswag --mode 1 --k 32  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc  
python test_llama.py --llama 2-7 --task hellaswag --mode 1 --k 64  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 2-7 --task hellaswag --mode 1 --k 128 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 2-7 --task hellaswag --mode 1 --k 256 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 2-7 --task hellaswag --mode 1 --k 512 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 2-7 --task hellaswag --mode 1 --k 16  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task hellaswag --mode 1 --k 32  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task hellaswag --mode 1 --k 64  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task hellaswag --mode 1 --k 128 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task hellaswag --mode 1 --k 256 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 2-7 --task hellaswag --mode 1 --k 512 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
# llama3-8B QA:
#   baseline (no sparsification)
python test_llama.py --llama 3-8 --task arc_challenge --mode 3 --timestamps
python test_llama.py --llama 3-8 --task arc_easy --mode 3 --timestamps
python test_llama.py --llama 3-8 --task hellaswag --mode 3 --timestamps
#   top-theta
python test_llama.py --llama 3-8 --task arc_challenge --mode 0 --k 16  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8 --task arc_challenge --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8 --task arc_challenge --mode 0 --k 64  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8 --task arc_challenge --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8 --task arc_challenge --mode 0 --k 256 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8 --task arc_challenge --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8 --task arc_challenge --mode 0 --k 16  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_challenge --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_challenge --mode 0 --k 64  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_challenge --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_challenge --mode 0 --k 256 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_challenge --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_easy --mode 0 --k 16  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc
python test_llama.py --llama 3-8 --task arc_easy --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc
python test_llama.py --llama 3-8 --task arc_easy --mode 0 --k 64  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc
python test_llama.py --llama 3-8 --task arc_easy --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc
python test_llama.py --llama 3-8 --task arc_easy --mode 0 --k 256 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc
python test_llama.py --llama 3-8 --task arc_easy --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc
python test_llama.py --llama 3-8 --task arc_easy --mode 0 --k 16  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_easy --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_easy --mode 0 --k 64  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_easy --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_easy --mode 0 --k 256 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_easy --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task hellaswag --mode 0 --k 16  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8 --task hellaswag --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8 --task hellaswag --mode 0 --k 64  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8 --task hellaswag --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8 --task hellaswag --mode 0 --k 256 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8 --task hellaswag --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8 --task hellaswag --mode 0 --k 16  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task hellaswag --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task hellaswag --mode 0 --k 64  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task hellaswag --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task hellaswag --mode 0 --k 256 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8 --task hellaswag --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
#   top-k
python test_llama.py --llama 3-8 --task arc_challenge --mode 1 --k 16  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-8 --task arc_challenge --mode 1 --k 32  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-8 --task arc_challenge --mode 1 --k 64  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-8 --task arc_challenge --mode 1 --k 128 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-8 --task arc_challenge --mode 1 --k 256 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-8 --task arc_challenge --mode 1 --k 512 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-8 --task arc_challenge --mode 1 --k 16  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_challenge --mode 1 --k 32  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_challenge --mode 1 --k 64  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_challenge --mode 1 --k 128 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_challenge --mode 1 --k 256 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_challenge --mode 1 --k 512 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_easy --mode 1 --k 16  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc
python test_llama.py --llama 3-8 --task arc_easy --mode 1 --k 32  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc
python test_llama.py --llama 3-8 --task arc_easy --mode 1 --k 64  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc
python test_llama.py --llama 3-8 --task arc_easy --mode 1 --k 128 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc
python test_llama.py --llama 3-8 --task arc_easy --mode 1 --k 256 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc
python test_llama.py --llama 3-8 --task arc_easy --mode 1 --k 512 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc
python test_llama.py --llama 3-8 --task arc_easy --mode 1 --k 16  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_easy --mode 1 --k 32  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_easy --mode 1 --k 64  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_easy --mode 1 --k 128 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_easy --mode 1 --k 256 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task arc_easy --mode 1 --k 512 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task hellaswag --mode 1 --k 16  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-8 --task hellaswag --mode 1 --k 32  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc  
python test_llama.py --llama 3-8 --task hellaswag --mode 1 --k 64  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-8 --task hellaswag --mode 1 --k 128 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-8 --task hellaswag --mode 1 --k 256 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-8 --task hellaswag --mode 1 --k 512 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-8 --task hellaswag --mode 1 --k 16  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task hellaswag --mode 1 --k 32  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task hellaswag --mode 1 --k 64  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task hellaswag --mode 1 --k 128 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task hellaswag --mode 1 --k 256 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-8 --task hellaswag --mode 1 --k 512 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
# llama 2-70b - Q&A
#   baseline (no sparsification)
python test_llama.py --llama 3-70 --task arc_challenge --mode 3 --timestamps
python test_llama.py --llama 3-70 --task arc_easy --mode 3 --timestamps
python test_llama.py --llama 3-70 --task hellaswag --mode 3 --timestamps
#   top-theta
python test_llama.py --llama 3-70 --task arc_challenge --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-70 --task arc_challenge --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-70 --task arc_challenge --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-70 --task arc_challenge --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-70 --task arc_challenge --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-70 --task arc_challenge --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-70 --task arc_easy --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-70 --task arc_easy --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-70 --task arc_easy --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-70 --task arc_easy --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-70 --task arc_easy --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-70 --task arc_easy --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-70 --task hellaswag --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc   
python test_llama.py --llama 3-70 --task hellaswag --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc
python test_llama.py --llama 3-70 --task hellaswag --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc  
python test_llama.py --llama 3-70 --task hellaswag --mode 0 --k 32  --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact 
python test_llama.py --llama 3-70 --task hellaswag --mode 0 --k 128 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact 
python test_llama.py --llama 3-70 --task hellaswag --mode 0 --k 512 --layerk 0:512,1:512 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact 
#   top-k
python test_llama.py --llama 3-70 --task arc_challenge --mode 1 --k 32  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-70 --task arc_challenge --mode 1 --k 128 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-70 --task arc_challenge --mode 1 --k 512 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-70 --task arc_challenge --mode 1 --k 32  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-70 --task arc_challenge --mode 1 --k 128 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-70 --task arc_challenge --mode 1 --k 512 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-70 --task arc_easy --mode 1 --k 32  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-70 --task arc_easy --mode 1 --k 128 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-70 --task arc_easy --mode 1 --k 512 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-70 --task arc_easy --mode 1 --k 32  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-70 --task arc_easy --mode 1 --k 128 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-70 --task arc_easy --mode 1 --k 512 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-70 --task hellaswag --mode 1 --k 32  --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-70 --task hellaswag --mode 1 --k 128 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-70 --task hellaswag --mode 1 --k 512 --layerk 0:512,1:512 --placement post-softmax --timestamps --vmc 
python test_llama.py --llama 3-70 --task hellaswag --mode 1 --k 32  --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-70 --task hellaswag --mode 1 --k 128 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact
python test_llama.py --llama 3-70 --task hellaswag --mode 1 --k 512 --layerk 0:512,1:512 --placement pre-softmax  --timestamps --vmc --sdc exact


```

## Human-eval - generative tasks
First run the experiments. Each run will be uniquely identified by a TIMESTAMP, its statistics will be dumped into a subdirectory `products/<TIMESTAMP>`, the pass@1 score will be written alongside the TIMESTAMP inside the results-Llama directory, in a text file. After you run the experiments - you can visualzie the pass@1 as a function of kept attention elements and as a function of kept V-rows by using `notebooks/5-accuracy-kept_attn-kept_vrow-tradeoff_humaneval.ipynb` - just update the TIMESTAMPS of the corresponding runs that you want to plot.
```bash
# LLaMA-3-8B-Instruct
#   baseline (no sparsification)
python gen_llama.py --timestamps --llama 2-70 --mode 3 --max_seq_len 2048 --prompt_prefix "#<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an expert programmer that helps to complete Python code based on the initial function name and docstring from the user initial.<|eot_id|><|start_header_id|>user<|end_header_id|>Complete the following Python function according to its docstring. After the function code is complete do not write any following tests or invocations of this function, do not repeat the implementation again. Finish your text after you finish the function code.<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
#    Top-k
python gen_llama.py --timestamps --llama 3-8i --mode 1 --k 32  --layerk 0:512,1:512 --placement pre-softmax --sdc exact --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 1 --k 64  --layerk 0:512,1:512 --placement pre-softmax --sdc exact --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 1 --k 128 --layerk 0:512,1:512 --placement pre-softmax --sdc exact --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 1 --k 256 --layerk 0:512,1:512 --placement pre-softmax --sdc exact --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 1 --k 512 --layerk 0:512,1:512 --placement pre-softmax --sdc exact --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 1 --k 32  --layerk 0:512,1:512 --placement post-softmax --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 1 --k 64  --layerk 0:512,1:512 --placement post-softmax --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 1 --k 128 --layerk 0:512,1:512 --placement post-softmax --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 1 --k 256 --layerk 0:512,1:512 --placement post-softmax --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 1 --k 512 --layerk 0:512,1:512 --placement post-softmax --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
#    Top-theta - with calibrating the thresholds on humaneval itself
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 32  --layerk 0:256,1:256 --placement pre-softmax --sdc exact --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 64  --layerk 0:256,1:256 --placement pre-softmax --sdc exact --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 128 --layerk 0:256,1:256 --placement pre-softmax --sdc exact --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 256 --layerk 0:256,1:256 --placement pre-softmax --sdc exact --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 32  --layerk 0:256,1:256 --placement post-softmax --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 64  --layerk 0:256,1:256 --placement post-softmax --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 128 --layerk 0:256,1:256 --placement post-softmax --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 256 --layerk 0:256,1:256 --placement post-softmax --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
#   Top-theta with proper calibration on a different domain
#   step 1 - just calibrate thresholds for Top-theta of Llama-3-8i
python test_llama.py --llama 3-8i --task arc_challenge --mode 0 --k 32  --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8i --task arc_challenge --mode 0 --k 64  --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8i --task arc_challenge --mode 0 --k 128 --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8i --task arc_challenge --mode 0 --k 256 --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-8i --task arc_challenge --mode 0 --k 32  --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8i --task arc_challenge --mode 0 --k 64  --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8i --task arc_challenge --mode 0 --k 128 --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-8i --task arc_challenge --mode 0 --k 256 --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
#    step 2 - move the th.txt files to exp-10/thresholds/<specially named directory> where the directoy is named according to (k, pre/post/model,dataset) on which it was calibrated

#    step 3 -run 3-8i using thresholds calibrated on arc_challenge
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 32  --layerk 0:256,1:256 --placement pre-softmax --sdc exact --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-8B-Instruct_arc_challenge_placement-pre-softmax_k256,256,32
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 64  --layerk 0:256,1:256 --placement pre-softmax --sdc exact --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-8B-Instruct_arc_challenge_placement-pre-softmax_k256,256,64
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 128 --layerk 0:256,1:256 --placement pre-softmax --sdc exact --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-8B-Instruct_arc_challenge_placement-pre-softmax_k256,256,128
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 256 --layerk 0:256,1:256 --placement pre-softmax --sdc exact --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-8B-Instruct_arc_challenge_placement-pre-softmax_k256,256,256
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 32  --layerk 0:256,1:256 --placement post-softmax --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-8B-Instruct_arc_challenge_placement-post-softmax_k256,256,32
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 64  --layerk 0:256,1:256 --placement post-softmax --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-8B-Instruct_arc_challenge_placement-post-softmax_k256,256,64
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 128 --layerk 0:256,1:256 --placement post-softmax --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-8B-Instruct_arc_challenge_placement-post-softmax_k256,256,128
python gen_llama.py --timestamps --llama 3-8i --mode 0 --k 256 --layerk 0:256,1:256 --placement post-softmax --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-8B-Instruct_arc_challenge_placement-post-softmax_k256,256,256


# LLaMA-3-70B-Instruct HumanEval
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
#   baseline (no sparsification)
python gen_llama.py --timestamps --llama 3-70i --mode 3 --max_seq_len 2048 --prompt_prefix "#<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an expert programmer that helps to complete Python code based on the initial function name and docstring from the user initial.<|eot_id|><|start_header_id|>user<|end_header_id|>Complete the following Python function according to its docstring. After the function code is complete do not write any following tests or invocations of this function, do not repeat the implementation again. Finish your text after you finish the function code.<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
#   Top-k
python gen_llama.py --timestamps --llama 3-70i --mode 1 --k 16  --layerk 0:512,1:512 --placement pre-softmax --sdc exact --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-70i --mode 1 --k 32  --layerk 0:512,1:512 --placement pre-softmax --sdc exact --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-70i --mode 1 --k 64  --layerk 0:512,1:512 --placement pre-softmax --sdc exact --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-70i --mode 1 --k 128 --layerk 0:512,1:512 --placement pre-softmax --sdc exact --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-70i --mode 1 --k 256 --layerk 0:512,1:512 --placement pre-softmax --sdc exact --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-70i --mode 1 --k 16  --layerk 0:512,1:512 --placement post-softmax --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-70i --mode 1 --k 32  --layerk 0:512,1:512 --placement post-softmax --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-70i --mode 1 --k 64  --layerk 0:512,1:512 --placement post-softmax --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-70i --mode 1 --k 128 --layerk 0:512,1:512 --placement post-softmax --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
python gen_llama.py --timestamps --llama 3-70i --mode 1 --k 256 --layerk 0:512,1:512 --placement post-softmax --vmc --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
#   Top-theta with proper calibration on a different domain
#   step 1 - just calibrate thresholds for Top-theta of Llama-3-8i
python test_llama.py --llama 3-70i --task arc_challenge --mode 0 --k 16  --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-70i --task arc_challenge --mode 0 --k 32  --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-70i --task arc_challenge --mode 0 --k 64  --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-70i --task arc_challenge --mode 0 --k 128 --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-70i --task arc_challenge --mode 0 --k 256 --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement post-softmax --timestamps --calib_tac --vmc 
python test_llama.py --llama 3-70i --task arc_challenge --mode 0 --k 16  --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-70i --task arc_challenge --mode 0 --k 32  --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-70i --task arc_challenge --mode 0 --k 64  --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-70i --task arc_challenge --mode 0 --k 128 --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
python test_llama.py --llama 3-70i --task arc_challenge --mode 0 --k 256 --layerk 0:256,1:256 --calib_add_sigma 0.1 --placement pre-softmax  --timestamps --calib_tac --vmc --sdc exact
#   step 2 - move the th.txt files to exp-10/thresholds/<specially named directory> where the directoy is named according to (k, pre/post/model,dataset) on which it was calibrated

#   step 3 - run 3-70i using thresholds calibrated on arc_challenge
python gen_llama.py --timestamps --llama 3-70i --mode 0 --k 16  --layerk 0:256,1:256 --placement pre-softmax --sdc exact --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-70B-Instruct_arc_challenge_placement-pre-softmax_k256,256,16
python gen_llama.py --timestamps --llama 3-70i --mode 0 --k 32  --layerk 0:256,1:256 --placement pre-softmax --sdc exact --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-70B-Instruct_arc_challenge_placement-pre-softmax_k256,256,32
python gen_llama.py --timestamps --llama 3-70i --mode 0 --k 64  --layerk 0:256,1:256 --placement pre-softmax --sdc exact --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-70B-Instruct_arc_challenge_placement-pre-softmax_k256,256,64
python gen_llama.py --timestamps --llama 3-70i --mode 0 --k 128 --layerk 0:256,1:256 --placement pre-softmax --sdc exact --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-70B-Instruct_arc_challenge_placement-pre-softmax_k256,256,128
python gen_llama.py --timestamps --llama 3-70i --mode 0 --k 256 --layerk 0:256,1:256 --placement pre-softmax --sdc exact --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-70B-Instruct_arc_challenge_placement-pre-softmax_k256,256,256
python gen_llama.py --timestamps --llama 3-70i --mode 0 --k 16  --layerk 0:256,1:256 --placement post-softmax --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-70B-Instruct_arc_challenge_placement-post-softmax_k256,256,16
python gen_llama.py --timestamps --llama 3-70i --mode 0 --k 32  --layerk 0:256,1:256 --placement post-softmax --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-70B-Instruct_arc_challenge_placement-post-softmax_k256,256,32
python gen_llama.py --timestamps --llama 3-70i --mode 0 --k 64  --layerk 0:256,1:256 --placement post-softmax --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-70B-Instruct_arc_challenge_placement-post-softmax_k256,256,64
python gen_llama.py --timestamps --llama 3-70i --mode 0 --k 128 --layerk 0:256,1:256 --placement post-softmax --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-70B-Instruct_arc_challenge_placement-post-softmax_k256,256,128
python gen_llama.py --timestamps --llama 3-70i --mode 0 --k 256 --layerk 0:256,1:256 --placement post-softmax --vmc --calib_add_sigma 0.1 --calib_sample_frac 1.0 --calib_tac --num_samples_per_task 1 --max_seq_len 2048 --prompt_prefix $'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are an expert Python programmer. The user will give provide the beginning of the function an you need to complete the function code in a concise way, without repeating user prompt but rather smoothly continuing it (with proper indentation), without adding invocations of this function. Do not write tests or useless comments.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n' --prompt_suffix $'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' --calib_load_path experiments/10-acc-size-tradeoff/thresholds/Llama-3-70B-Instruct_arc_challenge_placement-post-softmax_k256,256,256
```